<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>空落单行雨</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-23T06:00:17.077Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Kongluo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hadoop生态圈(一) ----- Flume的使用</title>
    <link href="http://yoursite.com/2018/04/23/BigData-Flume/"/>
    <id>http://yoursite.com/2018/04/23/BigData-Flume/</id>
    <published>2018-04-23T03:55:39.000Z</published>
    <updated>2018-04-23T06:00:17.077Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/04/23/BigData-Flume/agent1.jpg" alt="单个Agent采集数据"><br><a id="more"></a></p><h3 id="Flume在集群中扮演的角色"><a href="#Flume在集群中扮演的角色" class="headerlink" title="Flume在集群中扮演的角色"></a>Flume在集群中扮演的角色</h3><h4 id="Flume框架简介"><a href="#Flume框架简介" class="headerlink" title="Flume框架简介"></a>Flume框架简介</h4><p>  ① Flume提供一个分布式的，可靠的，对大数据量的日志进行高效收集、聚集、移动的服务，Flume只能在Unix环境下运行。<br>  ②Flume可以采集文件，socket数据包等各种形式源数据，又可以将采集到的数据输出到HDFS、HBase、hive、kafka等众多外部存储系统中<br>  ③一般的采集需求，通过对flume的简单配置即可实现<br>  ④Flume针对特殊场景也具备良好的自定义扩展能力，因此，flume可以适用于大部分的日常数据采集场景</p><h4 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h4><p>  1、Flume分布式系统中最核心的角色是agent，Flume采集系统就是由一个个agent所连接起来形成<br>  2、每一个agent相当于一个数据传递员，内部有三个组件:<br>    a) Source:采集源，用于跟数据源对接，以获取数据<br>    b) Sink:下沉地，采集数据的传送目的，用于往下一级agent传递数据或者往最终存储系统传递数据<br>    c) Channel:angent内部的数据传输通道，用于从source将数据传递到sink<br>    <strong>Source 到 Channel 到 Sink之间传递数据的形式是Event事件；Event事件是一个数据流单元。</strong></p><ul><li><p>简单结构<br><strong>单个Agent采集数据</strong><br><img src="/2018/04/23/BigData-Flume/agent1.jpg" alt="单个Agent采集数据"></p></li><li><p>复杂结构<br><strong>多个Agent采集数据</strong><br><img src="/2018/04/23/BigData-Flume/agent2.png" alt="多个Agent采集数据"></p></li></ul><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><ul><li>Source<br>  用于采集数据，Source是生产数据流的地方，同时Source会将产生的数据流传输到Channel，这个有点类似于Java IO部分的Channel</li><li>Channel<br>  用于桥接Sources和Sinks，类似于一个队列</li><li>Sink<br>  从Channel收集数据，将数据写到目标源(可以是下一个Source，也可以是HDFS或者HBase)</li></ul><h4 id="传输单元"><a href="#传输单元" class="headerlink" title="传输单元"></a>传输单元</h4><ul><li>Event<br>  Flume数据传输的基本单元，以事件的形式将数据从源头送至目的地</li></ul><h4 id="传输过程"><a href="#传输过程" class="headerlink" title="传输过程"></a>传输过程</h4><p>source监控某个文件，文件产生新的数据，拿到该数据后，将数据封装在一个Event中，并put<br>到channel后commit提交，channel队列先出先进，Sink去Channel队列中拉取数据，然后写入<br>到HDFS或者HBase中。</p><h3 id="安装配置Flume"><a href="#安装配置Flume" class="headerlink" title="安装配置Flume"></a>安装配置Flume</h3><p>  flume-env.sh<br>  配置java的环境变量<br>  进入Flume的目录，修改conf下的flume-env.sh，在里面配置JAVA_HOME</p><h3 id="Flume帮助命令"><a href="#Flume帮助命令" class="headerlink" title="Flume帮助命令"></a>Flume帮助命令</h3><p>  $bin/flume-ng</p><h3 id="案例讲解"><a href="#案例讲解" class="headerlink" title="案例讲解"></a>案例讲解</h3><h4 id="案例一-Flume监听端口，输出端口数据"><a href="#案例一-Flume监听端口，输出端口数据" class="headerlink" title="案例一:Flume监听端口，输出端口数据"></a>案例一:Flume监听端口，输出端口数据</h4><p>  ① 创建Flume Agent配置文件flume-telnet.修改conf<br>  ② cp -a fllume-conf.properties.template flume-telnet.conf<br>  ③ 进入文件，写入如下内容<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> # Name the components on this agent（起名）</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source（监听端口的方式）</span><br><span class="line">a1.sources.r1.type = netcat（源数据的数据类型）</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></p><p>  a1是指agent缩写<br>  ④ 安装telnet工具(没有反应正常)<br>    $ sudo rpm -ivh telnet-server-0.17-59.el7.x86_64.rpm<br>    $ sudo rpm -ivh telnet-0.17-59.el7.x86_64.rpm</p><p>  ⑤首先判断44444端口是否被占用<br>    $ netstat -an | grep 44444</p><p>  ⑥先开启flume先听端口(flume家目录执行)<br>    $ bin/flume-ng agent –conf conf/ –name a1 –conf-file conf/flume-telnet.conf -Dflume.root.logger==INFO,console</p><p>  ⑦使用telnet工具向本机的44444端口发送内容(新开一个窗口执行，不需非要家目录，本窗口输入信息。另外窗口可以监听到）<br>    $ telnet localhost 44444</p><h4 id="案例二-监听上传Hive日志文件到HDFS"><a href="#案例二-监听上传Hive日志文件到HDFS" class="headerlink" title="案例二:监听上传Hive日志文件到HDFS"></a>案例二:监听上传Hive日志文件到HDFS</h4><p>  ① 拷贝Hadoop相关jar到Flume的lib目录下<br>    share/hadoop/common/lib/hadoop-auth-2.5.0-cdh5.3.6.jar<br>    share/hadoop/common/lib/commons-configuration-1.6.jar<br>    share/hadoop/mapreduce1/lib/hadoop-hdfs-2.5.0-cdh5.3.6.jar<br>    share/hadoop/common/hadoop-common-2.5.0-cdh5.3.6.jar<br>    $cp share/hadoop/common/lib/hadoop-auth-2.5.0-cdh5.3.6.jar  /opt/modules/apache-flume-1.5.0-cdh5.3.6-bin/lib<br>  ② 创建flume-hdfs.conf文件<br>    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">  # Name the components on this agent</span><br><span class="line">a2.sources = r2</span><br><span class="line">a2.sinks = k2</span><br><span class="line">a2.channels = c2</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a2.sources.r2.type = exec</span><br><span class="line">a2.sources.r2.command = tail -f /opt/modules/cdh/hive-0.13.1-cdh5.3.6/logs/hive.log</span><br><span class="line">a2.sources.r2.shell = /bin/bash -c</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a2.sinks.k2.type = hdfs</span><br><span class="line">a2.sinks.k2.hdfs.path = hdfs://192.168.122.20:8020/flume/%Y%m%d/%H</span><br><span class="line">#上传文件的前缀</span><br><span class="line">a2.sinks.k2.hdfs.filePrefix = events-hive-</span><br><span class="line">#是否按照时间滚动文件夹</span><br><span class="line">a2.sinks.k2.hdfs.round = true</span><br><span class="line">#多少时间单位创建一个新的文件夹</span><br><span class="line">a2.sinks.k2.hdfs.roundValue = 1</span><br><span class="line">#重新定义时间单位</span><br><span class="line">a2.sinks.k2.hdfs.roundUnit = hour</span><br><span class="line">#是否使用本地时间戳</span><br><span class="line">a2.sinks.k2.hdfs.useLocalTimeStamp = true</span><br><span class="line">#积攒多少个Event才flush到HDFS一次</span><br><span class="line">a2.sinks.k2.hdfs.batchSize = 1000</span><br><span class="line">#设置文件类型，可支持压缩</span><br><span class="line">a2.sinks.k2.hdfs.fileType = DataStream</span><br><span class="line">#多久生成一个新的文件</span><br><span class="line">a2.sinks.k2.hdfs.rollInterval = 600</span><br><span class="line">#设置每个文件的滚动大小</span><br><span class="line">a2.sinks.k2.hdfs.rollSize = 134217700</span><br><span class="line">#文件的滚动与Event数量无关</span><br><span class="line">a2.sinks.k2.hdfs.rollCount = 0</span><br><span class="line">#最小冗余数</span><br><span class="line">a2.sinks.k2.hdfs.minBlockReplicas = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a2.channels.c2.type = memory</span><br><span class="line">a2.channels.c2.capacity = 1000</span><br><span class="line">a2.channels.c2.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a2.sources.r2.channels = c2</span><br><span class="line">a2.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure></p><h4 id="案例三-Flume监听整个目录"><a href="#案例三-Flume监听整个目录" class="headerlink" title="案例三:Flume监听整个目录"></a>案例三:Flume监听整个目录</h4><p>① 创建配置文件flume-dir.conf<br>$ cp -a flume-hdfs.conf flume-dir.conf<br>② 文件内容<br>      <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">  a3.sources = r3</span><br><span class="line">a3.sinks = k3</span><br><span class="line">a3.channels = c3</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a3.sources.r3.type = spooldir</span><br><span class="line">a3.sources.r3.spoolDir = /opt/modules/cdh/apache-flume-1.5.0-cdh5.3.6-bin/upload</span><br><span class="line">a3.sources.r3.fileHeader = true</span><br><span class="line">#忽略所有以.tmp结尾的文件，不上传</span><br><span class="line">a3.sources.r3.ignorePattern = ([^ ]*\.tmp)</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a3.sinks.k3.type = hdfs</span><br><span class="line">a3.sinks.k3.hdfs.path = hdfs://192.168.122.20:8020/flume/upload/%Y%m%d/%H</span><br><span class="line">#上传文件的前缀</span><br><span class="line">a3.sinks.k3.hdfs.filePrefix = upload-</span><br><span class="line">#是否按照时间滚动文件夹</span><br><span class="line">a3.sinks.k3.hdfs.round = true</span><br><span class="line">#多少时间单位创建一个新的文件夹</span><br><span class="line">a3.sinks.k3.hdfs.roundValue = 1</span><br><span class="line">#重新定义时间单位</span><br><span class="line">a3.sinks.k3.hdfs.roundUnit = hour</span><br><span class="line">#是否使用本地时间戳</span><br><span class="line">a3.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line">#积攒多少个Event才flush到HDFS一次</span><br><span class="line">a3.sinks.k3.hdfs.batchSize = 1000</span><br><span class="line">#设置文件类型，可支持压缩</span><br><span class="line">a3.sinks.k3.hdfs.fileType = DataStream</span><br><span class="line">#多久生成一个新的文件</span><br><span class="line">a3.sinks.k3.hdfs.rollInterval = 600</span><br><span class="line">#设置每个文件的滚动大小</span><br><span class="line">a3.sinks.k3.hdfs.rollSize = 134217700</span><br><span class="line">#文件的滚动与Event数量无关</span><br><span class="line">a3.sinks.k3.hdfs.rollCount = 0</span><br><span class="line">#最小冗余数</span><br><span class="line">a3.sinks.k3.hdfs.minBlockReplicas = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a3.channels.c3.type = memory</span><br><span class="line">a3.channels.c3.capacity = 1000</span><br><span class="line">a3.channels.c3.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a3.sources.r3.channels = c3</span><br><span class="line">a3.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure></p><p>③ 执行测试<br>$ bin/flume-ng agent –conf conf/ –name a3 –conf-file conf/flume-dir.conf &amp;</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/04/23/BigData-Flume/agent1.jpg&quot; alt=&quot;单个Agent采集数据&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hadoop生态圈(二) ----- Kafka的使用(一)</title>
    <link href="http://yoursite.com/2018/04/23/BigData-Kafka/"/>
    <id>http://yoursite.com/2018/04/23/BigData-Kafka/</id>
    <published>2018-04-23T02:15:51.000Z</published>
    <updated>2018-04-23T08:33:03.706Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/04/23/BigData-Kafka/kafka.png" alt="Kafka内部实现原理"><br><a id="more"></a></p><h3 id="Kafka概述"><a href="#Kafka概述" class="headerlink" title="Kafka概述"></a>Kafka概述</h3><h4 id="Kafka是什么"><a href="#Kafka是什么" class="headerlink" title="Kafka是什么"></a>Kafka是什么</h4><p>  在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。<br>  1）Apache Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。<br>  2）Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。<br>  3）Kafka是一个分布式消息队列:生产者，消费者的功能。Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer，消息接受者称为Consumer，此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。<br>  4）无论是kafka集群，还是producer和consumer都依赖于zookeeper集群保存一些meta信息，来保证系统可用性。</p><h4 id="Kafka内部实现原理"><a href="#Kafka内部实现原理" class="headerlink" title="Kafka内部实现原理"></a>Kafka内部实现原理</h4><p>  <img src="/2018/04/23/BigData-Kafka/kafka.png" alt="Kafka内部实现原理"><br>  （1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）<br>  点对点模型通常是一个基于拉取或者轮询的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到,l客户端。这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。<br>  （2）发布/订阅模式（一对多，数据生产后，推送给所有订阅者）<br>  发布订阅模型则是一个基于推送的消息传送模型。发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，处于离线状态。</p><h4 id="为什么需要消息队列"><a href="#为什么需要消息队列" class="headerlink" title="为什么需要消息队列"></a>为什么需要消息队列</h4><p>  1）解耦：<br>  　　允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。<br>  2）冗余：<br>  消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。<br>  3）扩展性：<br>  因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。<br>  4）灵活性 &amp; 峰值处理能力：<br>  在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。<br>  5）可恢复性：<br>  系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。<br>  6）顺序保证：<br>  在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka保证一个Partition内的消息的有序性）<br>  7）缓冲：<br>  有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。<br>  8）异步通信：<br>  很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h4 id="Kafka架构"><a href="#Kafka架构" class="headerlink" title="Kafka架构"></a>Kafka架构</h4><p>  <img src="/2018/04/23/BigData-Kafka/kafka1.png" alt="Kafka架构"></p><p>  1）Producer ：消息生产者，就是向kafka broker发消息的客户端。<br>  2）Consumer ：消息消费者，向kafka broker取消息的客户端<br>  3）Topic ：可以理解为一个队列。<br>  4） Consumer Group （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个partion只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。<br>  5）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。<br>  6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。<br>  7）Offset：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/04/23/BigData-Kafka/kafka.png&quot; alt=&quot;Kafka内部实现原理&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>myFirstPageForTag</title>
    <link href="http://yoursite.com/2018/04/21/myFirstPageForTag/"/>
    <id>http://yoursite.com/2018/04/21/myFirstPageForTag/</id>
    <published>2018-04-20T18:54:35.000Z</published>
    <updated>2018-04-23T05:49:33.662Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

      
    
    </summary>
    
      <category term="thoughts" scheme="http://yoursite.com/categories/thoughts/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="Scala" scheme="http://yoursite.com/tags/Scala/"/>
    
      <category term="HDFS" scheme="http://yoursite.com/tags/HDFS/"/>
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>我的第一篇博客</title>
    <link href="http://yoursite.com/2018/04/20/first-one/"/>
    <id>http://yoursite.com/2018/04/20/first-one/</id>
    <published>2018-04-20T14:45:24.271Z</published>
    <updated>2018-04-23T05:56:05.581Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/04/20/first-one/bye.jpg" alt="Bye"><br><a id="more"></a></p><p><i class="icon-pencil"></i> <strong>个人感想</strong></p><h4 id="第一点"><a href="#第一点" class="headerlink" title="  第一点"></a><i class="icon-file"></i>  <strong>第一点</strong></h4><p>我很庆幸在2016毕业的那一年去了北京，我更庆幸在2018年离开了北京。走出校园后，经过这两年的社会的洗礼，我已然能轻易的分清楚所有的善与恶，好与坏，真与假。</p><h4 id="第二点"><a href="#第二点" class="headerlink" title="  第二点"></a><i class="icon-file"></i>  <strong>第二点</strong></h4><p>这辈子很短，<strong>真诚</strong>，比什么都重要。</p><h4 id="第三点"><a href="#第三点" class="headerlink" title="  第三点"></a><i class="icon-file"></i>  <strong>第三点</strong></h4><p><strong>实力</strong> 才是硬道理，永远不要做语言的巨人。</p><h4 id="第四点"><a href="#第四点" class="headerlink" title="  第四点"></a><i class="icon-file"></i>  <strong>第四点</strong></h4><p>不要给那些让你觉得恶心的人任何有机可乘的机会，因为时间很宝贵，要把时间给那些带给你温暖的人。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/04/20/first-one/bye.jpg&quot; alt=&quot;Bye&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>article title</title>
    <link href="http://yoursite.com/2018/04/20/article-title/"/>
    <id>http://yoursite.com/2018/04/20/article-title/</id>
    <published>2018-04-20T02:21:25.000Z</published>
    <updated>2018-04-20T02:21:25.894Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
</feed>
